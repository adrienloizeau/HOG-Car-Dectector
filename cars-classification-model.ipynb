{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-03T20:12:28.524069Z","iopub.execute_input":"2023-03-03T20:12:28.524521Z","iopub.status.idle":"2023-03-03T20:12:28.531047Z","shell.execute_reply.started":"2023-03-03T20:12:28.524475Z","shell.execute_reply":"2023-03-03T20:12:28.529560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\nclass config:\n    IMG_PATH = \"/kaggle/input/the-car-connection-picture-dataset\"\n    ORIGINAL_PROJECT_PATH =\"/kaggle/input/train-dataset/train\"\n    ORIGINAL_PROJECT_LABELS = \"/kaggle/input/train-dataset/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:32:08.712021Z","iopub.execute_input":"2023-03-03T22:32:08.713301Z","iopub.status.idle":"2023-03-03T22:32:08.718711Z","shell.execute_reply.started":"2023-03-03T22:32:08.713243Z","shell.execute_reply":"2023-03-03T22:32:08.717586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading the data in a dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torchvision.io import read_image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\n\nclass CarDataset(Dataset):\n    def __init__(self, img_dir, transform=None, target_transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.transform_img = transforms.Compose([transforms.ToTensor()])\n        self.files = []\n        self._get_files()\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img_path = Path(self.img_dir) / Path(self.files[idx])\n        image = read_image(img_path.as_posix())\n        if self.transform:\n            image = self.transform(image)\n        return image\n    \n    def _get_files(self):\n        p = Path(self.img_dir).glob('**/*')\n        self.files = sorted([x.name for x in p if x.is_file()])\n\n        \ncars_dataset = CarDataset(config.IMG_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T21:00:50.649919Z","iopub.execute_input":"2023-03-03T21:00:50.650399Z","iopub.status.idle":"2023-03-03T21:01:26.340914Z","shell.execute_reply.started":"2023-03-03T21:00:50.650361Z","shell.execute_reply":"2023-03-03T21:01:26.339512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.imshow(np.transpose(cars_dataset[0],(1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2023-03-03T21:01:51.032725Z","iopub.execute_input":"2023-03-03T21:01:51.033812Z","iopub.status.idle":"2023-03-03T21:01:51.369743Z","shell.execute_reply.started":"2023-03-03T21:01:51.033768Z","shell.execute_reply":"2023-03-03T21:01:51.368412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the dataset\n\n1. The size of all the images","metadata":{}},{"cell_type":"code","source":"cars_dataset.files[count]","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:01:03.382957Z","iopub.execute_input":"2023-03-03T22:01:03.383377Z","iopub.status.idle":"2023-03-03T22:01:03.391124Z","shell.execute_reply.started":"2023-03-03T22:01:03.383343Z","shell.execute_reply":"2023-03-03T22:01:03.390201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\nshapes = []\n\n# See the size of all the pictures\nfor count, im in tqdm(enumerate(cars_dataset)):\n    rgb, h, w = im.shape\n    shapes.append([cars_dataset.files[count],rgb, h , w])\n    \nshapes_df = pd.DataFrame(shapes,columns = [\"path\",\"RGB\",\"h\",\"w\"])\nshapes_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:07:04.355914Z","iopub.execute_input":"2023-03-03T22:07:04.356354Z","iopub.status.idle":"2023-03-03T22:08:53.072805Z","shell.execute_reply.started":"2023-03-03T22:07:04.356317Z","shell.execute_reply":"2023-03-03T22:08:53.071584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Unique values for the Heights:\",shapes_df[\"h\"].unique())\nprint(\"Unique values for the Width:\",shapes_df[\"w\"].unique())","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:09:15.984319Z","iopub.execute_input":"2023-03-03T22:09:15.984711Z","iopub.status.idle":"2023-03-03T22:09:15.993948Z","shell.execute_reply.started":"2023-03-03T22:09:15.984674Z","shell.execute_reply":"2023-03-03T22:09:15.992728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Widths are unique and not the heights","metadata":{}},{"cell_type":"code","source":"print(\"Heights:\", shapes_df[\"h\"].value_counts())\n\nfig, ax = plt.subplots()\nlabels = shapes_df[\"h\"].value_counts().index\nvalues = (shapes_df[\"h\"].value_counts() / len(shapes_df[\"h\"])) *100\nax.bar(labels, values,20)\nax.set_xlabel(\"Heigths\")\nax.set_ylabel(\"Percentage\")\nplt.title(\"Percentage of Heights\")","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:09:21.135413Z","iopub.execute_input":"2023-03-03T22:09:21.135828Z","iopub.status.idle":"2023-03-03T22:09:21.898256Z","shell.execute_reply.started":"2023-03-03T22:09:21.135794Z","shell.execute_reply":"2023-03-03T22:09:21.897193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**14000 data is enought for training a model, we will only keep the 213x320 datas**","metadata":{}},{"cell_type":"code","source":"final_df = shapes_df[\"path\"].loc[shapes_df[\"h\"] == 213]\nfinal_df","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:11:06.658666Z","iopub.execute_input":"2023-03-03T22:11:06.659366Z","iopub.status.idle":"2023-03-03T22:11:06.670598Z","shell.execute_reply.started":"2023-03-03T22:11:06.659323Z","shell.execute_reply":"2023-03-03T22:11:06.669457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### New dataset","metadata":{}},{"cell_type":"code","source":"cars_dataset.files = final_df.values","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:13:12.362102Z","iopub.execute_input":"2023-03-03T22:13:12.362529Z","iopub.status.idle":"2023-03-03T22:13:12.368843Z","shell.execute_reply.started":"2023-03-03T22:13:12.362488Z","shell.execute_reply":"2023-03-03T22:13:12.367874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cars_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:13:21.312202Z","iopub.execute_input":"2023-03-03T22:13:21.313126Z","iopub.status.idle":"2023-03-03T22:13:21.319729Z","shell.execute_reply.started":"2023-03-03T22:13:21.313066Z","shell.execute_reply":"2023-03-03T22:13:21.318399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Second part: labeling non car data","metadata":{}},{"cell_type":"markdown","source":"1. Importing the images","metadata":{}},{"cell_type":"code","source":"df_original_dataset_labels[\"bounding_boxes\"].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:38:32.446002Z","iopub.execute_input":"2023-03-03T22:38:32.446461Z","iopub.status.idle":"2023-03-03T22:38:32.456215Z","shell.execute_reply.started":"2023-03-03T22:38:32.446423Z","shell.execute_reply":"2023-03-03T22:38:32.454981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_original_dataset_labels = pd.read_csv(config.ORIGINAL_PROJECT_LABELS)\nempty_images = df_original_dataset_labels[\"bounding_boxes\"].isna().sum()\nprint(\"Number of images without any car:\",empty_images)\n\ndf_empty_images = df_original_dataset_labels.loc[df_original_dataset_labels[\"bounding_boxes\"].isna()]\nprint(len(df_empty_images))","metadata":{"execution":{"iopub.status.busy":"2023-03-03T22:36:47.298262Z","iopub.execute_input":"2023-03-03T22:36:47.298692Z","iopub.status.idle":"2023-03-03T22:36:47.317813Z","shell.execute_reply.started":"2023-03-03T22:36:47.298648Z","shell.execute_reply":"2023-03-03T22:36:47.316350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hog","metadata":{}},{"cell_type":"code","source":"#creating hog features\nfd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n                \tcells_per_block=(2, 2), visualize=True, multichannel=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T20:12:32.463527Z","iopub.execute_input":"2023-03-03T20:12:32.464101Z","iopub.status.idle":"2023-03-03T20:12:32.562256Z","shell.execute_reply.started":"2023-03-03T20:12:32.464060Z","shell.execute_reply":"2023-03-03T20:12:32.560234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}